# ğŸš€ LangChain Runnables Demo â€“ Parallel Social Post Generator

This project demonstrates practical hands-on experience with **LangChain 2.x Runnables**, showcasing how to build modular, composable LLM pipelines using `RunnableSequence` and `RunnableParallel`.

The script generates **two different social media posts in parallel** â€” a Tweet and a LinkedIn post â€” based on a user-provided topic.  
It also prints the **ASCII graph** of the chain, giving a visual understanding of the runnable flow.

---

## ğŸ§  What This Project Demonstrates

### âœ”ï¸ LangChain Concepts Used
- `PromptTemplate`
- `ChatOpenAI`
- `StrOutputParser`
- `RunnableSequence`
- `RunnableParallel`
- Runnable graph visualization (`print_ascii()`)

### âœ”ï¸ Skills Demonstrated
- Building runnable pipelines in LangChain  
- Running multiple LLM tasks *in parallel*  
- Handling outputs cleanly (tweet + LinkedIn post)  
- Using `.env` files for API key security  
- Writing clean, modular, production-style Python code  
- Using Git & GitHub professionally  

---

## ğŸ“‚ Project Structure

```text
/Langchain-parallel-social-post/
â”‚
â”œâ”€â”€ runnable_parallel.py        # Main project file (parallel Tweet + LinkedIn)
â”œâ”€â”€ runnable_sequence.py        # Demo for sequential runnable chain
â”œâ”€â”€ runnable_lambda.py          # Demo using RunnableLambda
â”œâ”€â”€ requirements.txt            # All dependencies
â”œâ”€â”€ .gitignore                  # Protects secrets (.env)
â””â”€â”€ .env                        # Your API key (not uploaded to GitHub)

![Chain Graph](assets/parallel_chain_graph.png)

